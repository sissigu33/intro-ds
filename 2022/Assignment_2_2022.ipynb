{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 2 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Random variable generation and transformation\n",
    "\n",
    "The purpose of this problem is to show that you can implement your own sampler, this will be built in the following three steps:\n",
    "\n",
    "1. [2p] Implement a Linear Congruential Generator where you tested out a good combination (a large $M$ with $a,b$ satisfying the Hull-Dobell (Thm 6.8)) of parameters. Follow the instructions in the code block.\n",
    "2. [2p] Using a generator construct random numbers from the uniform $[0,1]$ distribution.\n",
    "3. [4p] Using a uniform $[0,1]$ random generator, generate samples from \n",
    "\n",
    "$$p_0(x) = \\frac{\\pi}{2}|\\sin(2\\pi x)|, \\quad x \\in [0,1] \\enspace .$$\n",
    "\n",
    "Using the **Accept-Reject** sampler (**Algorithm 1** in TFDS notes) with sampling density given by the uniform $[0,1]$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem1_LCG(size=None, seed = 0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e. u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    XXX\n",
    "    \n",
    "    return XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem1_uniform(generator=None, period = 1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator and produces samples from the uniform [0,1] distribution according\n",
    "    to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of type generator(size,seed) and produces the same result as problem1_LCG, i.e. pseudo random numbers in the range {0,1,...,period-1}\n",
    "    period : the period of the generator\n",
    "    seed : the seed to be used in the generator provided\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the uniform pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    XXX\n",
    "    \n",
    "    return XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem1_accept_reject(uniformGenerator=None, n_iterations=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator that produces uniform pseudo random [0,1] numbers \n",
    "    and produces samples from (pi/2)*abs(sin(x*2*pi)) using an Accept-Reject\n",
    "    sampler with the uniform distribution as the proposal distribution.\n",
    "    Runs n_iterations\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of the type generator(size,seed) that produces uniform pseudo random\n",
    "    numbers from [0,1]\n",
    "    seed : the seed to be used in the generator provided\n",
    "    n_iterations : an integer denoting how many attempts should be made in the accept-reject sampler\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the pseudo random numbers with the specified distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    XXX\n",
    "    \n",
    "    return XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 2, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# If you managed to solve all three parts you can test the following code to see if it runs\n",
    "# you have to change the period to match your LCG though, this is marked as XXX.\n",
    "# It is a very good idea to check these things using the histogram function in sagemath\n",
    "# try with a larger number of samples, up to 10000 should run\n",
    "\n",
    "print(\"LCG output: %s\" % problem1_LCG(size=10, seed = 1))\n",
    "\n",
    "period = 2147483648\n",
    "\n",
    "print(\"Uniform sampler %s\" % problem1_uniform(generator=problem1_LCG, period = period, size=10, seed=1))\n",
    "\n",
    "uniform_sampler = lambda size,seed: problem1_uniform(generator=problem1_LCG, period = period, size=size, seed=seed)\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem1_accept_reject(uniformGenerator = uniform_sampler,n_iterations=20,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# If however you did not manage to implement either part 1 or part 2 but still want to check part 3, you can run the code below\n",
    "\n",
    "def testUniformGenerator(size,seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    return [random.uniform(0,1) for s in range(size)]\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem1_accept_reject(uniformGenerator=testUniformGenerator, n_iterations=20, seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Markovian travel\n",
    "\n",
    "The dataset `Travel Dataset - Datathon 2019` is a simulated dataset designed to mimic real corporate travel systems -- focusing on flights and hotels. The file is at `data/flights.csv`, i.e. you can use the path `data/flights.csv` from the notebook to access the file.\n",
    "\n",
    "1. [2p] In the first code-box \n",
    "    1. Load the csv from file `data/flights.csv`\n",
    "    2. Fill in the value of the variables as specified by their names.\n",
    "2. [2p] In the second code-box your goal is to estimate a Markov chain transition matrix for the travels of these users. For example, if we enumerate the cities according to alphabetical order, the first city `'Aracaju (SE)'` would correspond to $0$. Each row of the file corresponds to one flight, i.e. it has a starting city and an ending city. We model this as a stationary Markov chain, i.e. each user's travel trajectory is a realization of the Markov chain, $X_t$. Here, $X_t$ is the current city the user is at, at step $t$, and $X_{t+1}$ is the city the user travels to at the next time step. This means that to each row in the file there is a corresponding pair $(X_{t},X_{t+1})$. The stationarity assumption gives that for all $t$ there is a transition density $p$ such that $P(X_{t+1} = y | X_t = x) = p(x,y)$ (for all $x,y$). The transition matrix should be `n_cities` x `n_citites` in size.\n",
    "3. [2p] Use the transition matrix to compute out the stationary distribution.\n",
    "4. [2p] Given that we start in 'Aracaju (SE)' what is the probability that after 3 steps we will be back in 'Aracaju (SE)'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271888, 1335, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "flights_data = pd.read_csv('data/flights.csv')    \n",
    "citys= flights_data['from'].nunique()\n",
    "codes= flights_data['userCode'].nunique()\n",
    "observation= len(flights_data)\n",
    "\n",
    "\n",
    "\n",
    "number_of_cities = citys\n",
    "number_of_userCodes = codes\n",
    "number_of_observations = observation\n",
    "number_of_observations,number_of_userCodes,citys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is a very useful function that you can use for part 2. You have seen this before when parsing the\n",
    "# pride and prejudice book.\n",
    "\n",
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "\n",
    "    Param myDataList, a list of data.\n",
    "    Return a dictionary mapping each unique data value to its frequency count.'''\n",
    "\n",
    "    freqDict = {} # start with an empty dictionary\n",
    "\n",
    "    for res in myDataList:\n",
    "        if res in freqDict: # the data value already exists as a key\n",
    "                freqDict[res] = freqDict[res] + 1 # add 1 to the count using sage integers\n",
    "        else: # the data value does not exist as a key value\n",
    "            freqDict[res] = 1 # add a new key-value pair for this new data value, frequency 1\n",
    "\n",
    "    return freqDict # return the dictionary created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.12983559, 0.14487965, 0.23218891, 0.1057651 ,\n",
       "        0.13120567, 0.07570385, 0.07839029, 0.10203095],\n",
       "       [0.15702265, 0.        , 0.14675591, 0.25273726, 0.09704669,\n",
       "        0.12417557, 0.06478443, 0.06527178, 0.09220572],\n",
       "       [0.15520318, 0.12999309, 0.        , 0.23751007, 0.1019627 ,\n",
       "        0.12979164, 0.0695004 , 0.07252216, 0.10351675],\n",
       "       [0.15079296, 0.1357189 , 0.14398869, 0.        , 0.11705079,\n",
       "        0.13275294, 0.10131375, 0.10119162, 0.11719036],\n",
       "       [0.16544797, 0.1255253 , 0.14889057, 0.28193814, 0.        ,\n",
       "        0.12161708, 0.03992268, 0.0389141 , 0.07774416],\n",
       "       [0.16023622, 0.1253937 , 0.14796588, 0.24963911, 0.09494751,\n",
       "        0.        , 0.06223753, 0.06404199, 0.09553806],\n",
       "       [0.16758846, 0.1185846 , 0.14362177, 0.34534642, 0.05649718,\n",
       "        0.11281594, 0.        , 0.        , 0.05554564],\n",
       "       [0.17060337, 0.1174579 , 0.14733396, 0.33910196, 0.05413938,\n",
       "        0.11412535, 0.        , 0.        , 0.05723807],\n",
       "       [0.1607619 , 0.12012698, 0.15225397, 0.28431746, 0.07830688,\n",
       "        0.12325926, 0.03953439, 0.04143915, 0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cities = list(flights_data['from'])+list(flights_data['to'])\n",
    "unique_cities = sorted(set(cities)) # The unique cities\n",
    "n_cities = len(unique_cities) # The number of unique citites\n",
    "\n",
    "# Count the different transitions\n",
    "transitions =list(zip(flights_data['from'],flights_data['to'])) # A list containing tuples ex: ('Aracaju (SE)','Rio de Janeiro (RJ)') of all transitions in the text\n",
    "transition_counts = makeFreqDict(transitions)# A dictionary that counts the number of each transition \n",
    "# ex: ('Aracaju (SE)','Rio de Janeiro (RJ)'):4\n",
    "indexToCity = {index:city for index, city in enumerate(unique_cities)} # A dictionary that maps the n-1 number to the n:th unique_city,\n",
    "# ex: 0:'Aracaju (SE)'\n",
    "cityToIndex = {city:index for index, city in enumerate(unique_cities)} # The inverse function of indexToWord, \n",
    "# ex: 'Aracaju (SE)':0\n",
    "\n",
    "# Part 3, finding the maximum likelihood estimate of the transition matrix\n",
    "\n",
    "transition_matrix = np.zeros((n_cities,n_cities)) # a numpy array of size (n_cities,n_cities)\n",
    "\n",
    "# Filling in the transition matrix\n",
    "for (from_city, to_city), count in transition_counts.items():\n",
    "    from_index = cityToIndex[from_city]\n",
    "    to_index = cityToIndex[to_city]\n",
    "    transition_matrix[from_index, to_index] = count\n",
    "\n",
    "# Normalizing the transition matrix to make the rows sum to 1\n",
    "for i in range(n_cities):\n",
    "    row_sum = np.sum(transition_matrix[i, :])\n",
    "    if row_sum > 0:  # To avoid division by zero\n",
    "        transition_matrix[i, :] /= row_sum\n",
    "transition_matrix\n",
    "# The transition matrix should be ordered in such a way that\n",
    "# p_{'Aracaju (SE)','Rio de Janeiro (RJ)'} = transition_matrix[cityToIndex['Aracaju (SE)'],cityToIndex['Rio de Janeiro (RJ)']]\n",
    "# and represents the probability of travelling Aracaju (SE)->Rio de Janeiro (RJ)\n",
    "\n",
    "# Make sure that the transition_matrix does not contain np.nan from division by zero for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Recife (PE)', 'Florianopolis (SC)'): 7609,\n",
       " ('Florianopolis (SC)', 'Recife (PE)'): 7609,\n",
       " ('Brasilia (DF)', 'Florianopolis (SC)'): 7779,\n",
       " ('Florianopolis (SC)', 'Brasilia (DF)'): 7779,\n",
       " ('Aracaju (SE)', 'Salvador (BH)'): 2918,\n",
       " ('Salvador (BH)', 'Aracaju (SE)'): 2918,\n",
       " ('Aracaju (SE)', 'Campo Grande (MS)'): 5393,\n",
       " ('Campo Grande (MS)', 'Aracaju (SE)'): 5393,\n",
       " ('Brasilia (DF)', 'Aracaju (SE)'): 4833,\n",
       " ('Aracaju (SE)', 'Brasilia (DF)'): 4833,\n",
       " ('Recife (PE)', 'Sao Paulo (SP)'): 2912,\n",
       " ('Sao Paulo (SP)', 'Recife (PE)'): 2912,\n",
       " ('Brasilia (DF)', 'Campo Grande (MS)'): 4517,\n",
       " ('Campo Grande (MS)', 'Brasilia (DF)'): 4517,\n",
       " ('Brasilia (DF)', 'Sao Paulo (SP)'): 2838,\n",
       " ('Sao Paulo (SP)', 'Brasilia (DF)'): 2838,\n",
       " ('Brasilia (DF)', 'Salvador (BH)'): 2009,\n",
       " ('Salvador (BH)', 'Brasilia (DF)'): 2009,\n",
       " ('Recife (PE)', 'Natal (RN)'): 2894,\n",
       " ('Natal (RN)', 'Recife (PE)'): 2894,\n",
       " ('Brasilia (DF)', 'Natal (RN)'): 2987,\n",
       " ('Natal (RN)', 'Brasilia (DF)'): 2987,\n",
       " ('Recife (PE)', 'Salvador (BH)'): 1952,\n",
       " ('Salvador (BH)', 'Recife (PE)'): 1952,\n",
       " ('Recife (PE)', 'Campo Grande (MS)'): 4510,\n",
       " ('Campo Grande (MS)', 'Recife (PE)'): 4510,\n",
       " ('Brasilia (DF)', 'Recife (PE)'): 3822,\n",
       " ('Recife (PE)', 'Brasilia (DF)'): 3822,\n",
       " ('Aracaju (SE)', 'Sao Paulo (SP)'): 3798,\n",
       " ('Sao Paulo (SP)', 'Aracaju (SE)'): 3798,\n",
       " ('Aracaju (SE)', 'Natal (RN)'): 3937,\n",
       " ('Natal (RN)', 'Aracaju (SE)'): 3937,\n",
       " ('Aracaju (SE)', 'Recife (PE)'): 4884,\n",
       " ('Recife (PE)', 'Aracaju (SE)'): 4884,\n",
       " ('Aracaju (SE)', 'Rio de Janeiro (RJ)'): 2818,\n",
       " ('Rio de Janeiro (RJ)', 'Aracaju (SE)'): 2818,\n",
       " ('Aracaju (SE)', 'Florianopolis (SC)'): 8643,\n",
       " ('Florianopolis (SC)', 'Aracaju (SE)'): 8643,\n",
       " ('Brasilia (DF)', 'Rio de Janeiro (RJ)'): 1994,\n",
       " ('Rio de Janeiro (RJ)', 'Brasilia (DF)'): 1994,\n",
       " ('Recife (PE)', 'Rio de Janeiro (RJ)'): 1897,\n",
       " ('Rio de Janeiro (RJ)', 'Recife (PE)'): 1897,\n",
       " ('Campo Grande (MS)', 'Florianopolis (SC)'): 8253,\n",
       " ('Florianopolis (SC)', 'Campo Grande (MS)'): 8253,\n",
       " ('Campo Grande (MS)', 'Salvador (BH)'): 2520,\n",
       " ('Salvador (BH)', 'Campo Grande (MS)'): 2520,\n",
       " ('Campo Grande (MS)', 'Sao Paulo (SP)'): 3597,\n",
       " ('Sao Paulo (SP)', 'Campo Grande (MS)'): 3597,\n",
       " ('Campo Grande (MS)', 'Natal (RN)'): 3543,\n",
       " ('Natal (RN)', 'Campo Grande (MS)'): 3543,\n",
       " ('Campo Grande (MS)', 'Rio de Janeiro (RJ)'): 2415,\n",
       " ('Rio de Janeiro (RJ)', 'Campo Grande (MS)'): 2415,\n",
       " ('Natal (RN)', 'Rio de Janeiro (RJ)'): 950,\n",
       " ('Rio de Janeiro (RJ)', 'Natal (RN)'): 950,\n",
       " ('Sao Paulo (SP)', 'Salvador (BH)'): 979,\n",
       " ('Salvador (BH)', 'Sao Paulo (SP)'): 979,\n",
       " ('Sao Paulo (SP)', 'Natal (RN)'): 1850,\n",
       " ('Natal (RN)', 'Sao Paulo (SP)'): 1850,\n",
       " ('Sao Paulo (SP)', 'Rio de Janeiro (RJ)'): 934,\n",
       " ('Rio de Janeiro (RJ)', 'Sao Paulo (SP)'): 934,\n",
       " ('Sao Paulo (SP)', 'Florianopolis (SC)'): 6717,\n",
       " ('Florianopolis (SC)', 'Sao Paulo (SP)'): 6717,\n",
       " ('Natal (RN)', 'Salvador (BH)'): 926,\n",
       " ('Salvador (BH)', 'Natal (RN)'): 926,\n",
       " ('Natal (RN)', 'Florianopolis (SC)'): 6709,\n",
       " ('Florianopolis (SC)', 'Natal (RN)'): 6709,\n",
       " ('Florianopolis (SC)', 'Rio de Janeiro (RJ)'): 5807,\n",
       " ('Rio de Janeiro (RJ)', 'Florianopolis (SC)'): 5807,\n",
       " ('Florianopolis (SC)', 'Salvador (BH)'): 5800,\n",
       " ('Salvador (BH)', 'Florianopolis (SC)'): 5800}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = list(flights_data['from']) + list(flights_data['to'])\n",
    "unique_cities = sorted(set(cities))  # The unique cities\n",
    "n_cities = len(unique_cities)  # The number of unique cities\n",
    "\n",
    "# Creating a mapping from city names to indices and vice versa\n",
    "indexToCity = {index: city for index, city in enumerate(unique_cities)}\n",
    "cityToIndex = {city: index for index, city in enumerate(unique_cities)}\n",
    "\n",
    "# Creating a list of all transitions\n",
    "transitions = list(zip(flights_data['from'], flights_data['to']))\n",
    "\n",
    "# Counting the different transitions using the provided makeFreqDict function\n",
    "def makeFreqDict(myDataList):\n",
    "    freqDict = {}\n",
    "    for res in myDataList:\n",
    "        if res in freqDict:\n",
    "            freqDict[res] += 1\n",
    "        else:\n",
    "            freqDict[res] = 1\n",
    "    return freqDict\n",
    "\n",
    "transition_counts = makeFreqDict(transitions)\n",
    "\n",
    "# Creating an empty transition matrix\n",
    "transition_matrix = np.zeros((n_cities, n_cities))\n",
    "\n",
    "# Filling in the transition matrix\n",
    "for (from_city, to_city), count in transition_counts.items():\n",
    "    from_index = cityToIndex[from_city]\n",
    "    to_index = cityToIndex[to_city]\n",
    "    transition_matrix[from_index, to_index] = count\n",
    "\n",
    "# Normalizing the transition matrix to make the rows sum to 1\n",
    "for i in range(n_cities):\n",
    "    row_sum = np.sum(transition_matrix[i, :])\n",
    "    if row_sum > 0:  # To avoid division by zero\n",
    "        transition_matrix[i, :] /= row_sum\n",
    "\n",
    "# Displaying a small portion of the transition matrix for verification\n",
    "transition_counts # Displaying the first 5 rows and columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13690932, 0.1132047 , 0.12780262, 0.21081107, 0.08752133,\n",
       "       0.11210498, 0.06184532, 0.06290826, 0.0868924 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This should be a numpy array of length n_cities which sums to 1 and is all positive\n",
    "A = (transition_matrix.T-np.eye(9))\n",
    "A[-1:]=1\n",
    "b = np.array([0,0,0,0,0,0,0,0,1])\n",
    "stationary_distribution_problem2 = np.linalg.solve(A,b)\n",
    "# the answer should be a numpy array of length 3\n",
    "# make sure that the entries sums to 1!\n",
    "stationary_distribution_problem2 \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13331717737273133"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_step_transition = np.linalg.matrix_power(transition_matrix,3)\n",
    "probability1 = three_step_transition[0,0]\n",
    "# Compute the return probability for part 3 of PROBLEM 2\n",
    "\n",
    "return_probability_problem2 = probability1\n",
    "return_probability_problem2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 2, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Once you have created all your functions, you can make a small test here to see\n",
    "# what would be generated from your model.\n",
    "import numpy as np\n",
    "\n",
    "start = np.zeros(shape=(n_cities,1))\n",
    "start[cityToIndex['Aracaju (SE)'],0] = 1\n",
    "\n",
    "current_pos = start\n",
    "for i in range(10):\n",
    "    random_word_index = np.random.choice(range(n_cities),p=current_pos.reshape(-1))\n",
    "    current_pos = np.zeros_like(start)\n",
    "    current_pos[random_word_index] = 1\n",
    "    print(indexToCity[random_word_index],end='->')\n",
    "    current_pos = (current_pos.T@transition_matrix).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "4"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 3\n",
    "Maximum Points = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "4"
   },
   "source": [
    "\n",
    "\n",
    "Derive the maximum likelihood estimate for $n$ IID samples from a random variable with the following probability density function:\n",
    "$$\n",
    "f(x; \\lambda) = \\frac{1}{24} \\lambda^5 x^4 \\exp(-\\lambda x), \\qquad \\text{ where, } \\lambda>0, x > 0\n",
    "$$\n",
    "\n",
    "You can solve the MLe by hand (using pencil paper or using key-strokes). Present your solution as the return value of a function called `def MLeForAssignment2Problem3(x)`, where `x` is a list of $n$ input data points.\n",
    "The probability density function (PDF) is given by:\n",
    "\n",
    "$$\n",
    "f(x; \\lambda) = \\frac{1}{24} \\lambda^5 x^4 \\exp(-\\lambda x), \\qquad \\text{where } \\lambda > 0, x > 0\n",
    "$$\n",
    "\n",
    "To derive the maximum likelihood estimate (MLE) for \\( n \\) IID samples from a random variable with the above PDF, we follow these steps:\n",
    "\n",
    "1. The likelihood function for all \\( n \\) samples is:\n",
    "$$\n",
    "L(\\lambda) = \\left( \\frac{1}{24} \\lambda^5 \\right)^n \\prod_{i=1}^{n} x_i^4 \\exp(-\\lambda x_i)\n",
    "$$\n",
    "\n",
    "2. The log-likelihood function is:\n",
    "$$\n",
    "\\ell(\\lambda) = n \\ln \\left( \\frac{1}{24} \\right) + 5n \\ln(\\lambda) + 4 \\sum_{i=1}^{n} \\ln(x_i) - \\lambda \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "3. Taking the derivative of the log-likelihood function with respect to \\( \\lambda \\) and setting it to zero gives us:\n",
    "$$\n",
    "\\frac{d}{d\\lambda} \\ell(\\lambda) = \\frac{5n}{\\lambda} - \\sum_{i=1}^{n} x_i = 0\n",
    "$$\n",
    "\n",
    "4. Solving for \\( \\lambda \\), we find the MLE:\n",
    "$$\n",
    "\\lambda = \\frac{5n}{\\sum_{i=1}^{n} x_i}\n",
    "$$\n",
    "\n",
    "This \\( \\lambda \\) is the MLE for the given PDF, under the assumption that the second derivative of the log-likelihood is negative, confirming that it is indeed a maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# do not change the name of the function, just replace XXX with the appropriate expressions for the MLe\n",
    "def MLeForAssignment2Problem3(x):\n",
    "    '''write comment of what this function does'''\n",
    "    def MLeForAssignment2Problem3(x):\n",
    "    n = len(x)\n",
    "    sum_x = sum(x)\n",
    "    lambda_mle = 5 * n / sum_x\n",
    "    return lambda_mle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "4"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 4\n",
    "Maximum Points = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "4"
   },
   "source": [
    "\n",
    "Use the **Multi-dimensional Constrained Optimisation** example (in `07-Optimization.ipynb`) to numerically find the MLe for the mean and variance parameter based on `normallySimulatedDataSamples`, an array obtained by a specific simulation of $30$ IID samples from the $Normal(10,2)$ random variable.\n",
    "\n",
    "Recall that $Normal(\\mu, \\sigma^2)$ RV has the probability density function given by:\n",
    "\n",
    "$$\n",
    "f(x ;\\mu, \\sigma) = \\displaystyle\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(\\frac{-1}{2\\sigma^2}(x-\\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "The two parameters, $\\mu \\in \\mathbb{R} := (-\\infty,\\infty)$ and $\\sigma \\in (0,\\infty)$, are sometimes referred to as the location and scale parameters.\n",
    "\n",
    "You know that the log likelihood function for $n$ IID samples from a Normal RV with parameters $\\mu$ and $\\sigma$ simply follows from $\\sum_{i=1}^n \\log(f(x_i; \\mu,\\sigma))$, based on the IID assumption. \n",
    "\n",
    "NOTE: When setting bounding boxes for $\\mu$ and $\\sigma$ try to start with some guesses like $[-20,20]$ and $[0.1,5.0]$ and make it larger if the solution is at the boundary. Making the left bounding-point for $\\sigma$ too close to $0.0$ will cause division by zero Warnings. Other numerical instabilities can happen in such iterative numerical solutions to the MLe. You need to be patient and learn by trial-and-error. You will see the mathematical theory in more details in a future course in scientific computing/optimisation. So don't worry too much now except learning to use it for our problems.  \n",
    "\n",
    "Given a set of \\( n \\) independent and identically distributed (IID) samples \\( \\{x_1, x_2, \\ldots, x_n\\} \\) from a normal distribution with mean \\( \\mu \\) and standard deviation \\( \\sigma \\), the probability density function (PDF) is given by:\n",
    "\n",
    "$$\n",
    "f(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x - \\mu}{\\sigma}\\right)^2\\right)\n",
    "$$\n",
    "\n",
    "The log-likelihood for the sample is the sum of the logarithms of the individual densities:\n",
    "\n",
    "$$\n",
    "\\ell(\\mu, \\sigma) = \\sum_{i=1}^{n} \\ln f(x_i; \\mu, \\sigma)\n",
    "$$\n",
    "\n",
    "The negative log-likelihood is then:\n",
    "\n",
    "$$\n",
    "-\\ell(\\mu, \\sigma) = -\\sum_{i=1}^{n} \\ln f(x_i; \\mu, \\sigma)\n",
    "$$\n",
    "\n",
    "Substituting the PDF into the log-likelihood function, we get:\n",
    "\n",
    "$$\n",
    "-\\ell(\\mu, \\sigma) = -\\sum_{i=1}^{n} \\ln \\left(\\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x_i - \\mu}{\\sigma}\\right)^2\\right)\\right)\n",
    "$$\n",
    "\n",
    "Simplifying, we have:\n",
    "\n",
    "$$\n",
    "-\\ell(\\mu, \\sigma) = n\\ln(\\sigma \\sqrt{2\\pi}) + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "To find the maximum likelihood estimates of \\( \\mu \\) and \\( \\sigma \\), we would seek to minimize this negative log-likelihood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "# do NOT change the next three lines\n",
    "np.random.seed(123456) # set seed\n",
    "# simulate 30 IID samples drawn from Normal(10,2)RV\n",
    "normallySimulatedDataSamples = np.random.normal(10,2,30) \n",
    "\n",
    "# define the negative log likelihoo function you want to minimise by editing XXX\n",
    "def neg_log_likelihood(params, data):\n",
    "    mu, sigma_squared = params\n",
    "    sigma = np.sqrt(sigma_squared)  # Convert variance to standard deviation\n",
    "    n = len(data)\n",
    "    nll = n * np.log(sigma * np.sqrt(2 * np.pi)) + (1/(2 * sigma_squared)) * np.sum((data - mu)**2)\n",
    "    return nll\n",
    "\n",
    "\n",
    "# you should only change XXX below and not anything else\n",
    "bounds = [(-np.inf, np.inf), (1e-6, np.inf)]\n",
    "\n",
    "# Initial guesses for mu and sigma_squared\n",
    "initial_params = [np.mean(normallySimulatedDataSamples), np.var(normallySimulatedDataSamples)]\n",
    "\n",
    "# Perform the minimization to find the MLE for mu and sigma_squared\n",
    "result = minimize(\n",
    "    fun=neg_log_likelihood,\n",
    "    x0=initial_params,\n",
    "    args=(normallySimulatedDataSamples,),\n",
    "    bounds=bounds\n",
    ")\n",
    "\n",
    "# Display the result of optimization\n",
    "print(result)\n",
    "\n",
    "result_Ass2Prob4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "lx_assignment_number": 2,
  "lx_course_instance": "2022",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
